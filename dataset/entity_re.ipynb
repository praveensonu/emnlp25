{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c721dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from groq import Groq\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b778c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/Shiyu-Lab/Wikipedia_Person_Unlearn/forget_20_1/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1dcb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key = \"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert teacher, who can create questions and answers from a given context. \n",
    "Given the user wikipedia page context about {domain_person_name}, please provide as many questions and answers possible from it.\n",
    "For each section, provide atleast 2 questions and answers.\n",
    "The question and answers should follow the Interrogative syntactic structure, \n",
    "\n",
    "The questions should be on their birth, family background, education, career, achievements and other relevant topics.\n",
    "\n",
    "The output should be in JSON format with the following keys:\n",
    "\n",
    "{{\n",
    "    \"name\": name of the person,\n",
    "    \"question1\": question1,\n",
    "    \"answer1\": answer1,\n",
    "    \"section\" : part of the wikipedia section,\n",
    "    \"difficulty\" : difficulty of the question,\n",
    "    \"question2\": question2,\n",
    "    .................\n",
    "}}\n",
    "\n",
    "Please be precise with the question and answer. Do not generate any other text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "{content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d75fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['new_questions'] = ''\n",
    "for i, row in final_df.iterrows():\n",
    "    name = row['SimilarName']\n",
    "    content = row['content']\n",
    "    questions = row['questions']\n",
    "    title = row['title']\n",
    "    \n",
    "    sys_prompt = system_prompt.format(domain_person_name=name)\n",
    "    prompt_text = prompt.format(content=content)\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt_text},]\n",
    "    print(\"Now generating for \", name)\n",
    "    response = client.chat.completions.create(\n",
    "        messages= messages,\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.1,\n",
    "        max_completion_tokens=1000\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "    final_df.at[i, 'new_questions'] = response_text\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
