{
    "vanilla_grad_diff": {
        "forget_efficacy": 0.9711538853019881,
        "model_utility_retain": 0.30615882610352396,
        "model_utility_test": 0.3511145304029041,
        "forget_scores": [
            0.0,
            0.00020408163265306123,
            0.08633426246138251
        ],
        "retain_scores": [
            0.1670114651715001,
            0.45534981898386795,
            0.6191532768030908
        ],
        "test_scores": [
            0.1834848518982551,
            0.5849148633809386,
            0.7222673444829497
        ],
        "qa_perplexity_forget": 1e+308,
        "qa_perplexity_retain": 5.827822685241699,
        "test_perplexity": 3.8095638751983643,
        "exp_type": "vanilla_grad_diff",
        "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "batch_size": 4,
        "num_epochs": 4,
        "lr": 2e-05,
        "weight_decay": 0.01,
        "LoRA_r": 8,
        "LoRA_alpha": 16
    }
}